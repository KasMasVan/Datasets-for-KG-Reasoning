# source
[Natural Questions: a Benchmark for Question Answering Research](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/1f7b46b5378d757553d3e92ead36bda2e4254244.pdf)
# description
>Questions consist of real anonymized, aggregated queries
issued to the Google search engine. An annotator is presented with a question along
with a Wikipedia page from the top 5 search
results, and annotates a long answer (typically a paragraph) and a short answer (one
or more entities) if present on the page,
or marks null if no long/short answer is
present.
# statistics
>The public release consists of
307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples 5-way annotated sequestered as test data
# example
![image](https://user-images.githubusercontent.com/51369075/97144547-98755f80-179f-11eb-8be4-bb8c35f4e612.png)
# referenced by
[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
