# source
[GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](https://arxiv.org/abs/1804.07461)
# description
>The General Language Understanding Evaluation
(GLUE) benchmark (Wang et al., 2018a) is a collection of diverse natural language understanding
tasks.

Please refer to Appendix B.1 of the BERT paper for more detail.
# statistics

# example

# referenced by
