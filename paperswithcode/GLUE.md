# source
[GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](https://arxiv.org/abs/1804.07461)
# description
>The General Language Understanding Evaluation
(GLUE) benchmark (Wang et al., 2018a) is a collection of diverse natural language understanding
tasks.

Please refer to Appendix B.1 of the BERT paper for more detail.
# statistics
![image](https://user-images.githubusercontent.com/51369075/97247058-d2933f80-1839-11eb-96ce-5e9062a2c177.png)
# example
Please refer to the 'source' paper for more detail.
# referenced by
[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805v2.pdf)
