# source
[Reasoning With Neural Tensor Networksfor Knowledge Base Completion](http://papers.nips.cc/paper/5028-reasoning-with-neural-tensor-networks-for-knowledge-base-completion.pdf)
# description
## WordNet
>For WordNet we use 112,581 relational triplets for
>training. In total, there are 38,696 unique entities in 11 different relations. One important >difference to previous work is our dataset generation which filters trivial test triplets.
>We filter out tuples from the testing set if either or both of their two entities also appear in the >training set in a different relation or order. For instance, if (e1,similar to, e2) appears in training >set, we delete (e2,similar to, e1) and (e1, type of, e2), etc from the testing set. In the case of >synsets containing multiple words, we pick the first, most frequent one.
## FreeBase
>For FreeBase, we use the relational triplets from People domain, and
>extract 13 relations. We remove 6 of them (place of death, place of birth, location, parents, children,
>spouse) from the testing set since they are very difficult to predict, e.g., the name of somebodyâ€™s
>spouse is hard to infer from other knowledge in the database.

# statistics
![image](https://user-images.githubusercontent.com/51369075/96971516-cbbdb180-1547-11eb-86ac-ce45cf637189.png)
# example
omitted
# referenced by
[Probability Calibration for Knowledge Graph Embedding Models](https://openreview.net/pdf?id=S1g8K1BFwS)
