# source
[Reasoning With Neural Tensor Networksfor Knowledge Base Completion](http://papers.nips.cc/paper/5028-reasoning-with-neural-tensor-networks-for-knowledge-base-completion.pdf)
# description
For WordNet the authors use 112,581 relational triplets for training. One important difference to previous work is that their dataset generation which filters trivial triplets
>We filter out tuples from the testing set if either or both of their two entities also appear in the ??>training set in a different relation or order. For instance, if (e1,similar to, e2) appears in training >set, we delete (e2,similar to, e1) and (e1, type of, e2), etc from the testing set. In the case of >synsets containing multiple words, we pick the first, most frequent one.
# statistics
![image](https://user-images.githubusercontent.com/51369075/96971516-cbbdb180-1547-11eb-86ac-ce45cf637189.png)
# example

# referenced by
